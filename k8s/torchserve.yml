#@ load("@ytt:data", "data")

apiVersion: apps/v1
kind: Deployment
metadata:
  name: torchserve
  namespace: inference
  labels:
    app.kubernetes.io/name: torchserve
    release: kube-prom-stack
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: torchserve
  template:
    metadata:
      labels:
        app.kubernetes.io/name: torchserve
        release: kube-prom-stack
    spec:
      containers:
        - name: torchserve-torchserve
          image: localhost:32000/torchserve-train:latest
          command: ["torchserve"]
          args:
          - --model-store
          - /var/ml/data/torchserve/
          - --models
          - all
          - --foreground
          - --start
          - --no-config-snapshots
          ports:
            - containerPort: 8080
              name: inference
            - containerPort: 8081
              name: management
            - containerPort: 8082
              name: metrics
          resources:
            limits:
              nvidia.com/gpu: "1"
          volumeMounts:
            - name: ml-volume
              mountPath: /var/ml/data
      volumes:
        - name: ml-volume
          hostPath:
            path: #@ data.values.model_dir
            type: Directory